{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset\n",
    "Here we use a dataset built into Tensorflow - the CIFR Image Dataset. <br>\n",
    "It contains 60,000 32*32 colored images of 10 different everyday objects (classes), with 6,000 images in each class. <br><br>\n",
    "The 10 everyday objects/classes are:\n",
    "- Airplane\n",
    "- Automobile\n",
    "- Bird\n",
    "- Cat\n",
    "- Deer\n",
    "- Dog\n",
    "- Frog\n",
    "- Horse\n",
    "- Ship\n",
    "- Truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load & split data\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context \n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# normalise pixel values to be between 0 & 1\n",
    "train_images, test_images = train_images/255.0, test_images/255.0\n",
    "#train_images, test_images = train_images, test_images\n",
    "\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "                'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at 1 image\n",
    "IMG_INDEX = 3\n",
    "\n",
    "plt.imshow(train_images[IMG_INDEX], cmap=plt.cm.binary)\n",
    "plt.xlabel(class_names[train_labels[IMG_INDEX][0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model (CNN Architecture)\n",
    "### a) Convolutional Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "# 32 = no. of filters\n",
    "# (3,3) = dimension of each filter\n",
    "# input_shape = (height, width, depth)\n",
    "# depth=3 means 3 color channels ie. RGB\n",
    "model.add(layers.MaxPooling2D(2,2))\n",
    "# max pooling operation using 2*2 samples with stride of 2\n",
    "# causes n*n dimensions to be reduced to (n/2)*(n/2) dimensions\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# the 2nd convolutional layer has 64 filters\n",
    "model.add(layers.MaxPooling2D(2,2))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With each max_pooling layer, our dimensions are reduced by half. <br>\n",
    "With each convolutional layer, we get 2 pixels less since we didn't use padding.\n",
    "### b) Adding Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten()) # depth of 64 becomes 1 line of 64 values\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10)) # 10 neurons for 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_images, train_labels, epochs=4,\n",
    "                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"3a) CNN.h5\")\n",
    "new_model = tf.keras.models.load_model('3a) CNN.h5')\n",
    "\n",
    "COLOR = 'white'\n",
    "plt.rcParams['text.color'] = COLOR\n",
    "plt.rcParams['axes.labelcolor'] = COLOR\n",
    "\n",
    "def predict(model, image, correct_label):\n",
    "    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "                'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    prediction = model.predict(np.array([image]))\n",
    "    predicted_class = class_names[np.argmax(prediction)]\n",
    "    \n",
    "    show_image(image, class_names[correct_label[0]], predicted_class)\n",
    "\n",
    "def show_image(img, label, guess):\n",
    "    plt.figure()\n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "    plt.colorbar()\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "    print('Actual: ' + label)\n",
    "    print('Predicted: '+ guess)\n",
    "\n",
    "def get_number(images):\n",
    "    while True:\n",
    "        num = input(\"Pick a number: \")\n",
    "        if num.isdigit() and 0<= int(num)<images.shape[0]:\n",
    "            return int(num)\n",
    "        else:\n",
    "            print('Try again...')\n",
    "\n",
    "num = get_number(test_images)\n",
    "image = test_images[num]\n",
    "label = test_labels[num]\n",
    "predict(new_model, image, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "# <b>Working with Small Datasets</b> (few thousand)\n",
    "### 1) Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create a data generator object that tranforms images\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Pick 1 image to transform\n",
    "test_img = train_images[14] \n",
    "img = image.img_to_array(test_img) # convert image to numpy array\n",
    "img = img.reshape((1,) + img.shape) # reshape image\n",
    "\n",
    "i = 0\n",
    "for batch in datagen.flow(img, save_prefix='test', save_format='jpeg'):\n",
    "    plt.figure(i)\n",
    "    plot = plt.imshow(image.img_to_array(batch[0]))\n",
    "    i += 1\n",
    "    if i > 4: break # show just 4 images\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pretrained Models\n",
    "Use pretrained models (eg. by Google) as base of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "keras = tf.keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()\n",
    "setattr(tfds.image_classification.cats_vs_dogs, '_URL',\"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\")\n",
    "\n",
    "# Split data manually into 80% training, 10% testing, 10% validation\n",
    "(raw_train, raw_validation, raw_test), metadata = tfds.load (\n",
    "    'cats_vs_dogs',\n",
    "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function object that we can use to get labels\n",
    "get_label_name = metadata.features['label'].int2str\n",
    "\n",
    "# Display 2 images from dataset\n",
    "for image, label in raw_train.take(2):\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    print(get_label_name(label))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing\n",
    "Since dimension of images are all different, we need to convert them to all the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All images will be resized to 160*160\n",
    "IMG_SIZE = 160 \n",
    "\n",
    "def format_example(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image/127.5) - 1\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    return image, label\n",
    "\n",
    "# Now we can apply this function to all our images using map\n",
    "train = raw_train.map(format_example)\n",
    "validation = raw_validation.map(format_example)\n",
    "test = raw_test.map(format_example)\n",
    "\n",
    "# Let's look at our images now\n",
    "for image, label in train.take(2):\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    print(get_label_name(label))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally we shuffle and batch the images\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER_SIZE = 1000\n",
    "\n",
    "train_batches = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "validation_batches = validation.batch(BATCH_SIZE)\n",
    "test_batches = test.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Picking a pretrained model\n",
    "The model we're using as our convolutional base is the <b>MobileNet V2</b> developed at Google. <br>\n",
    "This model is trained on 1.4 million images and has 1000 different classes. <br><br>\n",
    "We want to use this model but only its convolutional base. So when loading in the model, we'll specify we don't want to load the top (classification) layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "# Create base model from the pre-trained model MobileNet V2\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, _ in train_batches.take(1):\n",
    "    pass\n",
    "\n",
    "print(base_model(image).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point this base_model will simply output a shape (32, 5, 5, 1280) tensor that is a feature extraction from our original (1, 160, 160, 3) image. The 32 means that we have 32 layers of different filters/features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Freezing the base\n",
    "Freezing refers to disabling the training property of a layer. It means we won't make any changes to the weights of any layers that are frozen during training. This prevents changing the convolutional base that already has learned weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see now the \"Trainable params\" are 0.\n",
    "#### Adding our classifier\n",
    "Now we build our classifier upon the base layer. <br>\n",
    "Instead of flattening the feature map of the base layer we will use a global average pooling layer that will average the entire 5x5 area of each 2D feature map and return to us a single 1D 1280 element vector per filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we add a prediction layer that will be a single dense neuron. We can do this because we only have 2 classes to predict for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_layer = keras.layers.Dense(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we combine these layers together in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    global_average_layer,\n",
    "    prediction_layer\n",
    "])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate = how much are we allowed to modify weights & biases of this network\n",
    "base_learning_rate = 0.0001\n",
    "# we made it very low cuz we don't want to make any major changes since the model is already pretrained\n",
    "\n",
    "model2.compile(\n",
    "    optimizer = tf.keras.optimizers.RMSprop(lr=base_learning_rate),\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can evaluate our model right now to see how it goes before training it on our new images\n",
    "initial_epochs = 3\n",
    "validation_steps = 20\n",
    "\n",
    "loss0, accuracy0 = model2.evaluate(validation_batches, steps = validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the accuracy is close to 50%, like the model's merely guessing. This is normal since we haven't trained the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we train our model ie. modify weights & biases of the last 2 layers\n",
    "history = model2.fit(\n",
    "    train_batches,\n",
    "    epochs=initial_epochs,\n",
    "    validation_data=validation_batches\n",
    ")\n",
    "acc = history.history['accuracy']\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training our model, it's accuracy should be much closer to 100%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2.save(\"3b) dog_vs_cats.h5\")\n",
    "new_model2 = tf.keras.models.load_model('3b) dog_vs_cats.h5')\n",
    "\n",
    "COLOR = 'white'\n",
    "plt.rcParams['text.color'] = COLOR\n",
    "plt.rcParams['axes.labelcolor'] = COLOR\n",
    "\n",
    "def predict(model, image, correct_label):\n",
    "    class_names = ['cat', 'dog']\n",
    "    prediction = model.predict(np.array([image]))\n",
    "    predicted_class = \"dog\" if (prediction>0) else  \"cat\" if (prediction<0) else \"indeterminate\"\n",
    "\n",
    "    show_image(image, class_names[correct_label], predicted_class)\n",
    "\n",
    "def show_image(img, label, guess):\n",
    "    plt.figure()\n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "    plt.colorbar()\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "    print('Actual: ' + label)\n",
    "    print('Predicted: '+ guess)\n",
    "\n",
    "def resize(image):\n",
    "    IMG_SIZE = 160\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image/127.5) - 1\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    return image\n",
    "\n",
    "def retrieve(dataset, index):\n",
    "    i = 0\n",
    "    for image, label in dataset.take(index+1):\n",
    "        if (i==index):\n",
    "            return image, label\n",
    "        i += 1\n",
    "\n",
    "def get_number(size):\n",
    "    while True:\n",
    "        num = input(\"Pick a number: \")\n",
    "        if num.isdigit() and 0<= int(num)<size:\n",
    "            return int(num)\n",
    "        else:\n",
    "            print('Try again...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy:\", new_model2.evaluate(test_batches, steps = 20)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_size = sum(1 for _ in raw_train)\n",
    "num = get_number(ds_size)\n",
    "image, label = retrieve(raw_train, num)\n",
    "image = resize(image)\n",
    "predict(new_model2, image, label)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dc07d24e2f18896857f0b2a651fe84ba40ce7b297e58d8804a308c8039f752a6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
